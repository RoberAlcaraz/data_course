{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79bd3cd",
   "metadata": {},
   "source": [
    "# Profilers and optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b1cf1",
   "metadata": {},
   "source": [
    "![premature_opt](../images/donald_knuth_optimization.jpeg)\n",
    "\n",
    "Trying to do the optimization too early can be a futile time-waster.\n",
    "\n",
    "Spending too time/effort trying to\n",
    " * optimize functions that are going to be irrelevant later on\n",
    " * structure the code to scale before knowing what is going to be our \"maximum\"\n",
    "\n",
    "\n",
    "First it must run, if it takes too long to execute, then, we'll optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7e2da",
   "metadata": {},
   "source": [
    "## Profilers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbb94f",
   "metadata": {},
   "source": [
    "[cProfile](https://docs.python.org/3/library/profile.html#module-cProfile) and [profile](https://docs.python.org/3/library/profile.html#module-profile) provide deterministic profiling of Python programs. A profile is a set of statistics that describes how often and for how long various parts of the program executed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a178dc",
   "metadata": {},
   "source": [
    "The Python standard library provides two different implementations of the same profiling interface:\n",
    "\n",
    " * cProfile is recommended for most users; it’s a C extension with **reasonable overhead** that makes it suitable for profiling long-running programs\n",
    " * profile, a pure Python module whose interface is imitated by cProfile, but which **adds significant overhead** to profiled programs. If you’re trying to extend the profiler in some way, the task might be easier with this module.\n",
    "\n",
    "The profiler modules are designed to provide an execution profile for a given program, **not for benchmarking purposes** (for that, there is timeit for reasonably accurate results). This particularly applies to benchmarking Python code against C code: the profilers introduce overhead for Python code, but not for C-level functions, and so the C code would seem faster than any Python one.\n",
    "\n",
    "\n",
    "External usage:\n",
    "\n",
    "```\n",
    "python -m cProfile my_program.py\n",
    "python -m cProfile [-o output_file] [-s sort_order] (-m module | myscript.py)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Infile usage:\n",
    "\n",
    "Example1:\n",
    "```\n",
    "# importing cProfile\n",
    "import cProfile\n",
    " \n",
    "cProfile.run(\"10 + 10\")\n",
    "```\n",
    "Example2 (profiling a function):\n",
    "```\n",
    "import cProfile\n",
    "import pandas as pd\n",
    "cProfile.run(\"pd.Series(list('ABCDEFG'))\")\n",
    "```\n",
    "\n",
    "Ouput:\n",
    "```\n",
    "258 function calls (256 primitive calls) in 0.001 seconds\n",
    "Ordered by: standard name\n",
    "ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "     4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
    "     1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
    "     1    0.000    0.000    0.000    0.000 _dtype.py:319(_name_get)\n",
    "  ....\n",
    "  11/9    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
    "     1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
    "     1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
    "  ....\n",
    "```\n",
    "The first line indicates that 258 calls were monitored, out of which 256 were primitive (a primitive call is one that was not induced via recursion)\n",
    "\n",
    " * ncalls: number of calls made. when there are two numbers, the function recurred: total number of calls / number of primitive or non-recursive\n",
    " * tottime: total time spent in the given function (excluding subfunctions)\n",
    " * perclall: tottime/ncalls\n",
    " * cumtime: cumulative time in this and its subfuncions\n",
    " * percall: cumtime / primitive calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde2b45",
   "metadata": {},
   "source": [
    "## timeit\n",
    "\n",
    "This module provides a simple way to time small bits of Python code.\n",
    "\n",
    "```\n",
    "$ python3 -m timeit '\"-\".join(str(n) for n in range(100))'\n",
    "10000 loops, best of 5: 30.2 usec per loop\n",
    "$ python3 -m timeit '\"-\".join([str(n) for n in range(100)])'\n",
    "10000 loops, best of 5: 27.5 usec per loop\n",
    "$ python3 -m timeit '\"-\".join(map(str, range(100)))'\n",
    "10000 loops, best of 5: 23.2 usec per loop\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```\n",
    ">>> import timeit\n",
    ">>> timeit.timeit('\"-\".join(str(n) for n in range(100))', number=10000)\n",
    "0.3018611848820001\n",
    ">>> timeit.timeit('\"-\".join([str(n) for n in range(100)])', number=10000)\n",
    "0.2727368790656328\n",
    ">>> timeit.timeit('\"-\".join(map(str, range(100)))', number=10000)\n",
    "0.23702679807320237\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988cb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit \"-\".join(str(n) for n in range(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
